{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9628f1-7b94-4251-bd32-450ad22c2d60",
   "metadata": {},
   "source": [
    "# The First Model\n",
    "\n",
    "We are going to use the X_clustered.csv (constructed in data eng & feature selection notebook) file to train our first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aed7701-fc10-40cb-a851-5978b807a29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5241b7e-0cf7-4dba-9fce-4e343dbce226",
   "metadata": {},
   "source": [
    "## Loading the Clustered Data\n",
    "\n",
    "We will need the temporal order of test data, and for that, we use the file closest_rows.csv to reconstruct the time order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40680887-00b0-4686-8053-5177f38c0450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### training the model with the clustered data set\n",
    "\n",
    "train = pd.read_parquet('X_clustered.parquet')\n",
    "\n",
    "test = pd.read_parquet('X_clustered_test.parquet')\n",
    "\n",
    "row_id = pd.read_csv('closest_rows.csv', index_col=0)\n",
    "\n",
    "Y = pd.read_parquet('data/train.parquet')['label']\n",
    "\n",
    "new = test.reset_index()\n",
    "\n",
    "new['row_id'] = row_id['0']\n",
    "\n",
    "new = new.sort_values('row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d1e94bd-a7a5-47e3-ba40-dc84baddd67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = new.columns.tolist()[1:-1]\n",
    "\n",
    "X_test = new[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30221a-de6b-49d8-8318-0de3cca7e0d6",
   "metadata": {},
   "source": [
    "### Train & Val Data\n",
    "\n",
    "We use the last 100000 data poinst of train as our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "091877e0-e888-4eb5-b3c2-2dde52498096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### training the model with the original data set\n",
    "\n",
    "train = pd.read_parquet('data/train.parquet')\n",
    "\n",
    "Y = train['label']\n",
    "\n",
    "features = train.columns.tolist()[:-1]\n",
    "\n",
    "X = train[features]\n",
    "\n",
    "X_train = X[:-100000]\n",
    "\n",
    "Y_train = Y[:-100000]\n",
    "\n",
    "X_val = X[-100000:]\n",
    "\n",
    "Y_val = Y[-100000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba9e51-aaf5-47ff-898d-a347d5ae7674",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "Our model is going to be an ensemble of many linear regression models that are trained using the SGDRegressor in sklearn. Each linear regression model uses a fixed numbers of features(20 in the following code), and lagged versiosn of those features. The lag shift is chosen based on different temporal patterns, and we train a linear reg model for each pattern. The final model is the simple average of all these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c137ad5f-0cda-4f28-95cb-f50d72a49c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncrementalLagEnsemble:\n",
    "    \"\"\"Incrementally trains models on different lag configurations using SGD.\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_batch_size=20, lag_batch_size=5, n_epochs=9):\n",
    "        self.feature_batch_size = feature_batch_size\n",
    "        self.lag_batch_size = lag_batch_size\n",
    "        self.n_epochs = n_epochs  \n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_names = None\n",
    "        self.model_weights = {}\n",
    "        self.performance_history = defaultdict(list)\n",
    "        \n",
    "        # Define lag strategies with odd/even splits for many configurations\n",
    "        self.lag_strategies = {\n",
    "            # Original micro lags\n",
    "            'micro': [1, 2, 3, 4, 5],\n",
    "            'micro_odd': [1, 3, 5, 7, 9],\n",
    "            'micro_even': [2, 4, 6, 8, 10],\n",
    "            \n",
    "            # Ultra short with odd/even\n",
    "            'ultra_short': [6, 8, 10, 12, 15],\n",
    "            'ultra_short_odd': [7, 9, 11, 13, 15, 17],\n",
    "            'ultra_short_even': [6, 8, 10, 12, 14, 16],\n",
    "            \n",
    "            # Short with odd/even\n",
    "            'short': [20, 25, 30, 40, 50],\n",
    "            'short_odd': [21, 25, 31, 41, 51],\n",
    "            'short_even': [20, 24, 30, 40, 50],\n",
    "            \n",
    "            # Short medium with odd/even\n",
    "            'short_medium': [60, 75, 90, 105, 120],\n",
    "            'short_medium_odd': [61, 75, 91, 105, 121],\n",
    "            'short_medium_even': [60, 74, 90, 104, 120],\n",
    "            \n",
    "            # Medium with odd/even\n",
    "            'medium': [150, 180, 210, 240, 300],\n",
    "            'medium_odd': [151, 181, 211, 241, 301],\n",
    "            \n",
    "            # Medium long with odd/even\n",
    "            'medium_long': [360, 420, 480, 540, 600],\n",
    "            'medium_long_odd': [361, 421, 481, 541, 601],\n",
    "            \n",
    "            # Long with odd/even\n",
    "            'long': [720, 840, 960, 1080, 1200],\n",
    "            'long_odd': [721, 841, 961, 1081, 1201],\n",
    "            \n",
    "            # Very long with odd/even\n",
    "            'very_long': [1440, 1800, 2160, 2520, 2880],\n",
    "            'very_long_odd': [1441, 1801, 2161, 2521, 2881],\n",
    "            \n",
    "            # Ultra long (keeping original only due to very large values)\n",
    "            'ultra_long': [3600, 4320, 5040, 5760, 7200]\n",
    "        }\n",
    "        \n",
    "    def create_lag_features_batch(self, df, lag_list):\n",
    "        \"\"\"Create lag features for a batch of lags.\"\"\"\n",
    "        lag_features = []\n",
    "        \n",
    "        for lag in lag_list:\n",
    "            lagged = df.shift(-lag)\n",
    "            lagged.columns = [f'{col}_lag_{lag}' for col in df.columns]\n",
    "            lag_features.append(lagged)\n",
    "        \n",
    "        result = pd.concat([df] + lag_features, axis=1)\n",
    "        result = result.fillna(0)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def train_sgd_model(self, X, y, model_name):\n",
    "        \"\"\"Train SGD model incrementally with more epochs.\"\"\"\n",
    "        print(f\"  Training SGD model: {model_name} ({self.n_epochs} epochs)\")\n",
    "        \n",
    "        # Initialize model and scaler if not exists\n",
    "        if model_name not in self.models:\n",
    "            self.models[model_name] = SGDRegressor(\n",
    "                loss='huber',\n",
    "                penalty='elasticnet',\n",
    "                alpha=0.0001,\n",
    "                l1_ratio=0.15,\n",
    "                learning_rate='invscaling',\n",
    "                eta0=0.01,\n",
    "                power_t=0.25,\n",
    "                random_state=42,\n",
    "                warm_start=True,\n",
    "                max_iter=1000,\n",
    "                tol=1e-3\n",
    "            )\n",
    "            self.scalers[model_name] = StandardScaler()\n",
    "            \n",
    "        model = self.models[model_name]\n",
    "        scaler = self.scalers[model_name]\n",
    "        \n",
    "        # Train in epochs with smaller chunks for better convergence\n",
    "        chunk_size = 25000  # Slightly smaller chunks for more updates\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Shuffle indices for each epoch\n",
    "            indices = np.random.permutation(len(X))\n",
    "            \n",
    "            for start_idx in range(0, len(X), chunk_size):\n",
    "                end_idx = min(start_idx + chunk_size, len(X))\n",
    "                \n",
    "                # Get shuffled chunk\n",
    "                chunk_indices = indices[start_idx:end_idx]\n",
    "                X_chunk = X.iloc[chunk_indices]\n",
    "                y_chunk = y[chunk_indices]\n",
    "                \n",
    "                # Scale\n",
    "                if start_idx == 0 and epoch == 0:\n",
    "                    X_scaled = scaler.fit_transform(X_chunk)\n",
    "                else:\n",
    "                    X_scaled = scaler.transform(X_chunk)\n",
    "                \n",
    "                # Partial fit\n",
    "                model.partial_fit(X_scaled, y_chunk)\n",
    "            \n",
    "            # Print progress\n",
    "            if epoch % 3 == 0:\n",
    "                print(f\"    Epoch {epoch+1}/{self.n_epochs} completed\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train_feature_batch(self, feature_batch, X_full, y, strategy_name, lag_list):\n",
    "        \"\"\"Train on a batch of features with specific lags.\"\"\"\n",
    "        print(f\"\\n  Processing feature batch ({len(feature_batch)} features) with {strategy_name} lags\")\n",
    "        \n",
    "        # Select feature batch\n",
    "        X_batch = X_full[feature_batch].copy()\n",
    "        \n",
    "        # Create lag features\n",
    "        X_with_lags = self.create_lag_features_batch(X_batch, lag_list)\n",
    "        \n",
    "        # Train SGD model\n",
    "        model_name = f\"{strategy_name}_{feature_batch[0]}_{feature_batch[-1]}\"\n",
    "        self.train_sgd_model(X_with_lags, y, model_name)\n",
    "        \n",
    "        # Clean up\n",
    "        del X_batch, X_with_lags\n",
    "        gc.collect()\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit ensemble using incremental training.\"\"\"\n",
    "        print(\"Training Incremental Lag Ensemble with Odd/Even Lag Configurations...\")\n",
    "        print(f\"Total epochs per model: {self.n_epochs}\")\n",
    "        \n",
    "        self.feature_names = X.columns.tolist()\n",
    "        n_features = len(self.feature_names)\n",
    "        \n",
    "        # Split features into batches\n",
    "        feature_batches = []\n",
    "        for i in range(0, n_features, self.feature_batch_size):\n",
    "            batch = self.feature_names[i:i+self.feature_batch_size]\n",
    "            feature_batches.append(batch)\n",
    "        \n",
    "        print(f\"Split {n_features} features into {len(feature_batches)} batches\")\n",
    "        print(f\"Total lag strategies (including odd/even): {len(self.lag_strategies)}\")\n",
    "        \n",
    "        # Calculate total lag values\n",
    "        total_lags = sum(len(lags) for lags in self.lag_strategies.values())\n",
    "        print(f\"Total unique lag values: {total_lags}\")\n",
    "        \n",
    "        # Train models for each combination of feature batch and lag strategy\n",
    "        total_models = len(feature_batches) * len(self.lag_strategies)\n",
    "        model_count = 0\n",
    "        \n",
    "        for strategy_name, lag_list in self.lag_strategies.items():\n",
    "            print(f\"\\nTraining {strategy_name} strategy (lags: {lag_list})\")\n",
    "            \n",
    "            for batch_idx, feature_batch in enumerate(feature_batches):\n",
    "                model_count += 1\n",
    "                print(f\"Progress: {model_count}/{total_models} models\")\n",
    "                \n",
    "                self.train_feature_batch(feature_batch, X, y, strategy_name, lag_list)\n",
    "                \n",
    "                # Clean up periodically\n",
    "                if batch_idx % 2 == 0:\n",
    "                    gc.collect()\n",
    "        \n",
    "        # Initialize equal weights\n",
    "        for model_name in self.models:\n",
    "            self.model_weights[model_name] = 1.0 / len(self.models)\n",
    "        \n",
    "        print(f\"\\nTotal models trained: {len(self.models)}\")\n",
    "        \n",
    "    def predict_batch(self, X, feature_batch, strategy_name, lag_list):\n",
    "        \"\"\"Make predictions for a specific feature batch and lag strategy.\"\"\"\n",
    "        model_name = f\"{strategy_name}_{feature_batch[0]}_{feature_batch[-1]}\"\n",
    "        \n",
    "        if model_name not in self.models:\n",
    "            return None\n",
    "            \n",
    "        # Select features\n",
    "        X_batch = X[feature_batch].copy()\n",
    "        \n",
    "        # Create lag features\n",
    "        X_with_lags = self.create_lag_features_batch(X_batch, lag_list)\n",
    "        \n",
    "        # Scale and predict\n",
    "        X_scaled = self.scalers[model_name].transform(X_with_lags)\n",
    "        predictions = self.models[model_name].predict(X_scaled)\n",
    "        \n",
    "        # Clean up\n",
    "        del X_batch, X_with_lags, X_scaled\n",
    "        gc.collect()\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make ensemble predictions.\"\"\"\n",
    "        all_predictions = []\n",
    "        weights = []\n",
    "        \n",
    "        # Recreate feature batches\n",
    "        n_features = len(self.feature_names)\n",
    "        feature_batches = []\n",
    "        for i in range(0, n_features, self.feature_batch_size):\n",
    "            batch = self.feature_names[i:i+self.feature_batch_size]\n",
    "            if all(col in X.columns for col in batch):\n",
    "                feature_batches.append(batch)\n",
    "        \n",
    "        # Get predictions from each model\n",
    "        for strategy_name, lag_list in self.lag_strategies.items():\n",
    "            for feature_batch in feature_batches:\n",
    "                pred = self.predict_batch(X, feature_batch, strategy_name, lag_list)\n",
    "                if pred is not None:\n",
    "                    all_predictions.append(pred)\n",
    "                    model_name = f\"{strategy_name}_{feature_batch[0]}_{feature_batch[-1]}\"\n",
    "                    weights.append(self.model_weights.get(model_name, 1.0))\n",
    "        \n",
    "        # Weighted average\n",
    "        if all_predictions:\n",
    "            weights = np.array(weights) / np.sum(weights)\n",
    "            return np.average(all_predictions, axis=0, weights=weights)\n",
    "        else:\n",
    "            return np.zeros(len(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e21bb8-5da5-4f9d-b71d-7fac06d145f8",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "We train the model for 9 epochs (each SGDRegressor trains for 9 epochs). The model consists of 252 smaller linear regression models. We tried feature_batch_size = (15, 20, 25), and 20 gives the best validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19000c1b-e4b1-4a0c-a5e4-b53d7f774f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training with the original dataset\n",
    "\n",
    "ensemble_original = IncrementalLagEnsemble(\n",
    "    feature_batch_size=20,  \n",
    "    lag_batch_size=5,\n",
    "    n_epochs=9 \n",
    ")\n",
    "ensemble_original.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa3e8b-461e-4544-9a37-68d697d17644",
   "metadata": {},
   "source": [
    "## Run the Model on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ecb7204-f962-4778-897e-c97100fe2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e56e78a-3507-45f0-af2d-dab1ac52e70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new['pred'] = y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "831708a2-3fea-4634-a49e-a99513a9e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sorted = new.sort_values('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "998d8938-cf8e-4691-b5d3-4ae24425e34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>bid_qty</th>\n",
       "      <th>ask_qty</th>\n",
       "      <th>buy_qty</th>\n",
       "      <th>sell_qty</th>\n",
       "      <th>volume</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>row_id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.317</td>\n",
       "      <td>8.102</td>\n",
       "      <td>13.164</td>\n",
       "      <td>10.272</td>\n",
       "      <td>23.436</td>\n",
       "      <td>0.026487</td>\n",
       "      <td>0.053709</td>\n",
       "      <td>-0.095664</td>\n",
       "      <td>-0.832326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033602</td>\n",
       "      <td>1.217343</td>\n",
       "      <td>4.680540</td>\n",
       "      <td>1.386040</td>\n",
       "      <td>3.495303</td>\n",
       "      <td>2.506787</td>\n",
       "      <td>0.180057</td>\n",
       "      <td>0.982409</td>\n",
       "      <td>112334</td>\n",
       "      <td>-0.068603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.608</td>\n",
       "      <td>2.111</td>\n",
       "      <td>123.562</td>\n",
       "      <td>40.163</td>\n",
       "      <td>163.725</td>\n",
       "      <td>-0.021333</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>-0.101896</td>\n",
       "      <td>-0.704061</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.677375</td>\n",
       "      <td>-0.244482</td>\n",
       "      <td>3.746843</td>\n",
       "      <td>1.754129</td>\n",
       "      <td>0.531684</td>\n",
       "      <td>-0.339125</td>\n",
       "      <td>-0.398399</td>\n",
       "      <td>-0.936513</td>\n",
       "      <td>69300</td>\n",
       "      <td>0.180521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.768</td>\n",
       "      <td>10.787</td>\n",
       "      <td>126.137</td>\n",
       "      <td>118.266</td>\n",
       "      <td>244.403</td>\n",
       "      <td>0.108185</td>\n",
       "      <td>-0.021955</td>\n",
       "      <td>-0.089188</td>\n",
       "      <td>-0.226271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307522</td>\n",
       "      <td>0.529769</td>\n",
       "      <td>-0.875603</td>\n",
       "      <td>0.122851</td>\n",
       "      <td>-0.579363</td>\n",
       "      <td>0.143650</td>\n",
       "      <td>-0.203422</td>\n",
       "      <td>-0.047355</td>\n",
       "      <td>152075</td>\n",
       "      <td>-0.512381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.948</td>\n",
       "      <td>12.157</td>\n",
       "      <td>16.069</td>\n",
       "      <td>31.723</td>\n",
       "      <td>47.792</td>\n",
       "      <td>0.023319</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>-0.085059</td>\n",
       "      <td>-0.536935</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046230</td>\n",
       "      <td>0.533205</td>\n",
       "      <td>-0.198328</td>\n",
       "      <td>0.616502</td>\n",
       "      <td>0.105334</td>\n",
       "      <td>-0.043589</td>\n",
       "      <td>-0.123433</td>\n",
       "      <td>-0.093690</td>\n",
       "      <td>255828</td>\n",
       "      <td>-0.062439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.084</td>\n",
       "      <td>3.493</td>\n",
       "      <td>32.679</td>\n",
       "      <td>37.327</td>\n",
       "      <td>70.006</td>\n",
       "      <td>-0.108662</td>\n",
       "      <td>-0.095576</td>\n",
       "      <td>-0.111953</td>\n",
       "      <td>-0.500968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272161</td>\n",
       "      <td>1.456934</td>\n",
       "      <td>0.063305</td>\n",
       "      <td>0.877043</td>\n",
       "      <td>-0.852162</td>\n",
       "      <td>-0.592059</td>\n",
       "      <td>-0.659861</td>\n",
       "      <td>-0.166776</td>\n",
       "      <td>390226</td>\n",
       "      <td>-0.008075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  bid_qty  ask_qty  buy_qty  sell_qty   volume         1         2  \\\n",
       "0   1    0.317    8.102   13.164    10.272   23.436  0.026487  0.053709   \n",
       "1   2    2.608    2.111  123.562    40.163  163.725 -0.021333  0.007705   \n",
       "2   3    2.768   10.787  126.137   118.266  244.403  0.108185 -0.021955   \n",
       "3   4    0.948   12.157   16.069    31.723   47.792  0.023319  0.015206   \n",
       "4   5    1.084    3.493   32.679    37.327   70.006 -0.108662 -0.095576   \n",
       "\n",
       "          3         4  ...       167       168       169       170       171  \\\n",
       "0 -0.095664 -0.832326  ...  0.033602  1.217343  4.680540  1.386040  3.495303   \n",
       "1 -0.101896 -0.704061  ... -1.677375 -0.244482  3.746843  1.754129  0.531684   \n",
       "2 -0.089188 -0.226271  ...  0.307522  0.529769 -0.875603  0.122851 -0.579363   \n",
       "3 -0.085059 -0.536935  ... -0.046230  0.533205 -0.198328  0.616502  0.105334   \n",
       "4 -0.111953 -0.500968  ...  0.272161  1.456934  0.063305  0.877043 -0.852162   \n",
       "\n",
       "        172       173       174  row_id      pred  \n",
       "0  2.506787  0.180057  0.982409  112334 -0.068603  \n",
       "1 -0.339125 -0.398399 -0.936513   69300  0.180521  \n",
       "2  0.143650 -0.203422 -0.047355  152075 -0.512381  \n",
       "3 -0.043589 -0.123433 -0.093690  255828 -0.062439  \n",
       "4 -0.592059 -0.659861 -0.166776  390226 -0.008075  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92b213a2-6e2e-4c2e-8883-0c48420652b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.068603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.180521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.512381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.062439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-0.008075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  prediction\n",
       "0   1   -0.068603\n",
       "1   2    0.180521\n",
       "2   3   -0.512381\n",
       "3   4   -0.062439\n",
       "4   5   -0.008075"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = new_sorted['pred']\n",
    "\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "submission['prediction'] = y_pred.reset_index(drop=True)\n",
    "\n",
    "\n",
    "submission.to_csv('submission.csv', index = False)\n",
    "\n",
    "out = pd.read_csv('submission.csv')\n",
    "\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc861728-e7af-4e33-a356-23f0b25c24d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FineTune)",
   "language": "python",
   "name": "finetune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
